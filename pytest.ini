# pytest configuration for RangerIO Testing Suite
[pytest]
testpaths = rangerio_tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
asyncio_mode = auto

addopts = 
    -v
    --tb=short
    --strict-markers
    --html=reports/html/report.html
    --self-contained-html
    --timeout=90

# Global timeout: 90s for fast Granite models (Micro/Tiny)
timeout = 90
timeout_method = thread

markers =
    unit: Unit tests (fast, isolated)
    integration: Integration tests (requires RangerIO running)
    e2e: End-to-end UI tests
    load: Load testing (heavy)
    interactive: Requires human validation
    slow: Slow tests (skip with -m "not slow")
    performance: Performance benchmarking tests
    accuracy: Query accuracy validation tests
    filetype: File type specific tests (PDF, DOCX)
    sales: Sales data specific tests
    assistant: Assistant mode and smart features tests
    export: Export workflow tests (CSV, Excel generation)
    tasks: Task queue validation tests
    profiling: Performance profiling and memory tests
    stress: Stress tests (concurrent users, high load)
    quality: RAG quality and accuracy tests
    regression: Regression tests (golden queries that must pass)
    observability: Health checks, metrics, logging tests
    deep_search: Deep search mode tests
    diagnostics: Performance diagnostics with recommendations
    streaming: Streaming endpoint tests (tests what the UI actually uses)
    user_scenario: Realistic user scenario tests with accuracy validation
    batch1: Batch 1 - Financial Sample queries (~10 min)
    batch2: Batch 2 - Sales 5-Year comprehensive queries (~10 min)
    batch3: Batch 3 - PII Detection tests (~10 min)
    batch4: Batch 4 - Mixed Quality data tests (~10 min)
    batch5: Batch 5 - Multi-Source RAG cross-document analysis (~15 min)
    multisource: Multi-source RAG tests (queries across multiple data sources)
    all_batches: Run all user scenario batches



